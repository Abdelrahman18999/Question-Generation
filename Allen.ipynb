{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPSQy65pLBsK6uZVEnhbrun"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Allen Model"],"metadata":{"id":"OQK48iafBkGD"}},{"cell_type":"markdown","source":["### Import and download all the dependencies"],"metadata":{"id":"OxJldZ3hBn9x"}},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"-6uMT_LzWJ6z","executionInfo":{"status":"ok","timestamp":1663844714413,"user_tz":-120,"elapsed":233673,"user":{"displayName":"Abdelrahman Ahmed","userId":"01921622983923456487"}},"outputId":"02dbd33d-0073-4a36-96dd-1ae1d52e9f15"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting allennlp==2.1.0\n","  Downloading allennlp-2.1.0-py3-none-any.whl (585 kB)\n","\u001b[K     |████████████████████████████████| 585 kB 4.1 MB/s \n","\u001b[?25hCollecting allennlp-models==2.1.0\n","  Downloading allennlp_models-2.1.0-py3-none-any.whl (407 kB)\n","\u001b[K     |████████████████████████████████| 407 kB 43.0 MB/s \n","\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (8.14.0)\n","Collecting torchvision<0.9.0,>=0.8.1\n","  Downloading torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8 MB)\n","\u001b[K     |████████████████████████████████| 12.8 MB 35.7 MB/s \n","\u001b[?25hCollecting transformers<4.4,>=4.1\n","  Downloading transformers-4.3.3-py3-none-any.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 42.8 MB/s \n","\u001b[?25hCollecting spacy<3.1,>=2.1.0\n","  Downloading spacy-3.0.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 24.1 MB/s \n","\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (3.7)\n","Collecting boto3<2.0,>=1.14\n","  Downloading boto3-1.24.78-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 52.2 MB/s \n","\u001b[?25hCollecting jsonnet>=0.10.0\n","  Downloading jsonnet-0.18.0.tar.gz (592 kB)\n","\u001b[K     |████████████████████████████████| 592 kB 63.5 MB/s \n","\u001b[?25hRequirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (0.99)\n","Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (2.23.0)\n","Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (4.64.1)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (3.6.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (1.21.6)\n","Collecting torch<1.8.0,>=1.6.0\n","  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n","\u001b[K     |████████████████████████████████| 776.8 MB 12 kB/s \n","\u001b[?25hCollecting overrides==3.1.0\n","  Downloading overrides-3.1.0.tar.gz (11 kB)\n","Collecting jsonpickle\n","  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (1.7.3)\n","Collecting filelock<3.1,>=3.0\n","  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (3.1.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 32.3 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (1.0.2)\n","Collecting tensorboardX>=1.2\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 51.7 MB/s \n","\u001b[?25hCollecting py-rouge==1.1\n","  Downloading py_rouge-1.1-py3-none-any.whl (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 2.9 MB/s \n","\u001b[?25hCollecting conllu==4.4\n","  Downloading conllu-4.4-py2.py3-none-any.whl (15 kB)\n","Collecting ftfy\n","  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n","\u001b[K     |████████████████████████████████| 53 kB 1.4 MB/s \n","\u001b[?25hCollecting word2number>=1.1\n","  Downloading word2number-1.1.zip (9.7 kB)\n","Collecting s3transfer<0.7.0,>=0.6.0\n","  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 7.8 MB/s \n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting botocore<1.28.0,>=1.27.78\n","  Downloading botocore-1.27.78-py3-none-any.whl (9.1 MB)\n","\u001b[K     |████████████████████████████████| 9.1 MB 40.1 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.78->boto3<2.0,>=1.14->allennlp==2.1.0) (2.8.2)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 55.0 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.78->boto3<2.0,>=1.14->allennlp==2.1.0) (1.15.0)\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 56.5 MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==2.1.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==2.1.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==2.1.0) (2022.6.15)\n","Collecting thinc<8.1.0,>=8.0.3\n","  Downloading thinc-8.0.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n","\u001b[K     |████████████████████████████████| 660 kB 64.8 MB/s \n","\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (1.0.8)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (2.4.4)\n","Collecting typing-extensions<4.0.0.0,>=3.7.4\n","  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (3.0.7)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (57.4.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (0.10.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (2.0.6)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (3.0.10)\n","Collecting typer<0.4.0,>=0.3.0\n","  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n","Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n","  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n","\u001b[K     |████████████████████████████████| 10.1 MB 39.0 MB/s \n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (2.11.3)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (0.6.2)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (2.0.8)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (0.7.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (21.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.4->spacy<3.1,>=2.1.0->allennlp==2.1.0) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1,>=2.1.0->allennlp==2.1.0) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1,>=2.1.0->allennlp==2.1.0) (5.2.1)\n","Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=1.2->allennlp==2.1.0) (3.17.3)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision<0.9.0,>=0.8.1->allennlp==2.1.0) (7.1.2)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 41.0 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.4,>=4.1->allennlp==2.1.0) (2022.6.2)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 42.9 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<4.4,>=4.1->allennlp==2.1.0) (4.12.0)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1,>=2.1.0->allennlp==2.1.0) (7.1.2)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->allennlp-models==2.1.0) (0.2.5)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->allennlp==2.1.0) (1.5.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1,>=2.1.0->allennlp==2.1.0) (2.0.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->allennlp==2.1.0) (1.1.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==2.1.0) (1.4.1)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==2.1.0) (1.11.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==2.1.0) (22.1.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==2.1.0) (0.7.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->allennlp==2.1.0) (3.1.0)\n","Building wheels for collected packages: overrides, jsonnet, word2number, sacremoses\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=33ceeb918b66e4f3eb6afc88a987830ad387ff11c76c80cd4a0f94b84b5b9ada\n","  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n","  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jsonnet: filename=jsonnet-0.18.0-cp37-cp37m-linux_x86_64.whl size=3994724 sha256=74d6285265d8e687b43af1120716d3aa87b6aff6d446843ce9790231f26913ec\n","  Stored in directory: /root/.cache/pip/wheels/a9/63/f9/a653f9c21575e6ff271ee6a49939aa002005174cea6c35919d\n","  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5582 sha256=e1b09cc393430bde81ad57049a7ead1114a01dc4da8510c14f753c9f26163c7c\n","  Stored in directory: /root/.cache/pip/wheels/4b/c3/77/a5f48aeb0d3efb7cd5ad61cbd3da30bbf9ffc9662b07c9f879\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=39967ec1d84fa1817bb16e97ff7f4655166c9c380f2626538e40432193140e79\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built overrides jsonnet word2number sacremoses\n","Installing collected packages: typing-extensions, urllib3, jmespath, typer, pydantic, botocore, torch, tokenizers, thinc, sacremoses, s3transfer, filelock, transformers, torchvision, tensorboardX, spacy, sentencepiece, overrides, jsonpickle, jsonnet, boto3, word2number, py-rouge, ftfy, conllu, allennlp, allennlp-models\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing-extensions 4.1.1\n","    Uninstalling typing-extensions-4.1.1:\n","      Successfully uninstalled typing-extensions-4.1.1\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: typer\n","    Found existing installation: typer 0.4.2\n","    Uninstalling typer-0.4.2:\n","      Successfully uninstalled typer-0.4.2\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 1.9.2\n","    Uninstalling pydantic-1.9.2:\n","      Successfully uninstalled pydantic-1.9.2\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 8.1.0\n","    Uninstalling thinc-8.1.0:\n","      Successfully uninstalled thinc-8.1.0\n","  Attempting uninstall: filelock\n","    Found existing installation: filelock 3.8.0\n","    Uninstalling filelock-3.8.0:\n","      Successfully uninstalled filelock-3.8.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.13.1+cu113\n","    Uninstalling torchvision-0.13.1+cu113:\n","      Successfully uninstalled torchvision-0.13.1+cu113\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 3.4.1\n","    Uninstalling spacy-3.4.1:\n","      Successfully uninstalled spacy-3.4.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.7.1 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.7.1 which is incompatible.\n","en-core-web-sm 3.4.0 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.0.8 which is incompatible.\u001b[0m\n","Successfully installed allennlp-2.1.0 allennlp-models-2.1.0 boto3-1.24.78 botocore-1.27.78 conllu-4.4 filelock-3.0.12 ftfy-6.1.1 jmespath-1.0.1 jsonnet-0.18.0 jsonpickle-2.2.0 overrides-3.1.0 py-rouge-1.1 pydantic-1.8.2 s3transfer-0.6.0 sacremoses-0.0.53 sentencepiece-0.1.97 spacy-3.0.8 tensorboardX-2.5.1 thinc-8.0.17 tokenizers-0.10.3 torch-1.7.1 torchvision-0.8.2 transformers-4.3.3 typer-0.3.2 typing-extensions-3.10.0.2 urllib3-1.25.11 word2number-1.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["typing_extensions","urllib3"]}}},"metadata":{}}],"source":["! pip install allennlp==2.1.0 allennlp-models==2.1.0"]},{"cell_type":"code","source":["! pip install git+https://github.com/explosion/spacy-transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R1GP9CwiWXb_","executionInfo":{"status":"ok","timestamp":1663844776869,"user_tz":-120,"elapsed":14589,"user":{"displayName":"Abdelrahman Ahmed","userId":"01921622983923456487"}},"outputId":"a7e1b4fa-474b-4944-a001-104d715c6a0f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/explosion/spacy-transformers\n","  Cloning https://github.com/explosion/spacy-transformers to /tmp/pip-req-build-ktvoc49i\n","  Running command git clone -q https://github.com/explosion/spacy-transformers /tmp/pip-req-build-ktvoc49i\n","Collecting spacy<4.0.0,>=3.4.0\n","  Downloading spacy-3.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n","\u001b[K     |████████████████████████████████| 6.3 MB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: transformers<4.22.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers==1.1.8) (4.3.3)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers==1.1.8) (1.7.1)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers==1.1.8) (2.4.4)\n","Collecting spacy-alignments<1.0.0,>=0.7.2\n","  Downloading spacy_alignments-0.8.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 36.5 MB/s \n","\u001b[?25hRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (1.0.3)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (3.0.10)\n","Collecting thinc<8.2.0,>=8.1.0\n","  Downloading thinc-8.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (803 kB)\n","\u001b[K     |████████████████████████████████| 803 kB 62.5 MB/s \n","\u001b[?25hRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (1.8.2)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (3.10.0.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (2.23.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (2.0.8)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (4.64.1)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (0.6.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (57.4.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (21.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (3.0.7)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (3.3.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (1.21.6)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (2.0.6)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (0.3.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (1.0.8)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (2.11.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (0.10.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (5.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (1.25.11)\n","Requirement already satisfied: blis<0.10.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (0.7.8)\n","Collecting confection<1.0.0,>=0.0.1\n","  Downloading confection-0.0.1-py3-none-any.whl (32 kB)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers==1.1.8) (2022.6.2)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers==1.1.8) (0.0.53)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers==1.1.8) (3.0.12)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers==1.1.8) (0.10.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers==1.1.8) (4.12.0)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<4.0.0,>=3.4.0->spacy-transformers==1.1.8) (2.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.22.0,>=3.4.0->spacy-transformers==1.1.8) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.22.0,>=3.4.0->spacy-transformers==1.1.8) (1.1.0)\n","Building wheels for collected packages: spacy-transformers\n","  Building wheel for spacy-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for spacy-transformers: filename=spacy_transformers-1.1.8-py2.py3-none-any.whl size=54022 sha256=527e87da293de64ad746885c219add4dfd18a10ff03f99daf0c796dd2b22d529\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-zh5u9rkn/wheels/41/c7/fa/69c1c02ea4105ea96b79ae6fd88420690edc71fff25e514f05\n","Successfully built spacy-transformers\n","Installing collected packages: confection, thinc, spacy-alignments, spacy, spacy-transformers\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 8.0.17\n","    Uninstalling thinc-8.0.17:\n","      Successfully uninstalled thinc-8.0.17\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 3.0.8\n","    Uninstalling spacy-3.0.8:\n","      Successfully uninstalled spacy-3.0.8\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","allennlp 2.1.0 requires spacy<3.1,>=2.1.0, but you have spacy 3.4.1 which is incompatible.\u001b[0m\n","Successfully installed confection-0.0.1 spacy-3.4.1 spacy-alignments-0.8.5 spacy-transformers-1.1.8 thinc-8.1.1\n"]}]},{"cell_type":"markdown","source":["### Divide the DataFrame to contains only `Context` and `Questions` columns."],"metadata":{"id":"5GgqYSJrBux6"}},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv(\"context_ques.csv\")\n","sub_df = df[[\"Context\", \"Question\"]]\n","sub_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"URC2ID8UXsOG","executionInfo":{"status":"ok","timestamp":1663847725083,"user_tz":-120,"elapsed":361,"user":{"displayName":"Abdelrahman Ahmed","userId":"01921622983923456487"}},"outputId":"1ad8a68e-de4e-4fd1-97a4-6e206fa6f5ac"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             Context  \\\n","0  The technological discipline of computer visio...   \n","1  The technological discipline of computer visio...   \n","2  Recent advances in deep learning has enabled r...   \n","3  Recent advances in deep learning has enabled r...   \n","4  From the perspective of engineering, it seeks ...   \n","\n","                                            Question  \n","0       What are the types of computer vision tasks?  \n","1         What is the definition of computer vision?  \n","2  What is the role of the input to a device for ...  \n","3         What is the definition of computer vision?  \n","4         What is the definition of computer vision?  "],"text/html":["\n","  <div id=\"df-3f1c68a3-eadf-4a36-a4cd-4b02e51a27d3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Context</th>\n","      <th>Question</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>The technological discipline of computer visio...</td>\n","      <td>What are the types of computer vision tasks?</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>The technological discipline of computer visio...</td>\n","      <td>What is the definition of computer vision?</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Recent advances in deep learning has enabled r...</td>\n","      <td>What is the role of the input to a device for ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Recent advances in deep learning has enabled r...</td>\n","      <td>What is the definition of computer vision?</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>From the perspective of engineering, it seeks ...</td>\n","      <td>What is the definition of computer vision?</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f1c68a3-eadf-4a36-a4cd-4b02e51a27d3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3f1c68a3-eadf-4a36-a4cd-4b02e51a27d3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3f1c68a3-eadf-4a36-a4cd-4b02e51a27d3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["### How to iterate over these two columns together?"],"metadata":{"id":"hNz-qnz0B8F8"}},{"cell_type":"code","source":["for context, question in zip(sub_df.Context, sub_df.Question):\n","    print(context)\n","    print()\n","    print(question)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"osk9s3_v01qU","executionInfo":{"status":"ok","timestamp":1663847750836,"user_tz":-120,"elapsed":518,"user":{"displayName":"Abdelrahman Ahmed","userId":"01921622983923456487"}},"outputId":"85f49f1c-bae1-49b8-fa1d-47bc64f9f152"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["The technological discipline of computer vision seeks to apply its theories and models to the construction of computer vision systems.Subdomains of computer vision include scene reconstruction, object detection, event detection, video tracking, object recognition, D pose estimation, learning, indexing, motion estimation, visual servoing, D scene modeling, and image restoration.Computer vision is an interdisciplinary field that deals with how computers can be made to gain highlevel understanding from digital images or videos.From the perspective of engineering, it seeks to understand and automate tasks that the human visual system can do.Computer vision tasks include methods for acquiring, processing, analyzing and understanding digital images, and extraction of highdimensional data from the real world in order to produce numerical or symbolic information, e.g.Some examples of typical computer vision tasks are presented below.Computer vision tasks include methods for acquiring, processing, analyzing and understanding digital images, and extraction of highdimensional data from the real world in order to produce numerical or symbolic information, e.g., in the forms of decisions.Computer vision is an interdisciplinary scientific field that deals with how computers can gain highlevel understanding from digital images or videos.\n","\n","What are the types of computer vision tasks?\n"]}]},{"cell_type":"markdown","source":["### Now iterate over them and apply Allen on your DataFrame"],"metadata":{"id":"HzXj1_hpCDGO"}},{"cell_type":"code","source":["from allennlp.predictors.predictor import Predictor\n","import allennlp_models.rc\n","\n","# This dictionary holds all the Allen outputs\n","pred_dict = []\n","  \n","for context, question in zip(sub_df.Context, sub_df.Question):\n","  predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/bidaf-elmo.2021-02-11.tar.gz\")\n","  pred_dict.append(predictor.predict( passage= context, question= question))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2t-YA0FxbGvK","executionInfo":{"status":"ok","timestamp":1663848622742,"user_tz":-120,"elapsed":860028,"user":{"displayName":"Abdelrahman Ahmed","userId":"01921622983923456487"}},"outputId":"8b0d1e23-8c3f-4d4e-8353-c96f31e5f6c2"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n","  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n","/usr/local/lib/python3.7/dist-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n","  warnings.warn(Warnings.W108)\n"]}]},{"cell_type":"markdown","source":["### Build a list that contains all the question answers from Allen model which are the value of `best_span_str` key."],"metadata":{"id":"a8Nas9vHCUtV"}},{"cell_type":"code","source":["answers = []\n","for i in range(len(pred_dict)):\n","  answers.append(pred_dict[i]['best_span_str'])"],"metadata":{"id":"_sE0YWk78_4o","executionInfo":{"status":"ok","timestamp":1663848704422,"user_tz":-120,"elapsed":611,"user":{"displayName":"Abdelrahman Ahmed","userId":"01921622983923456487"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["## Check the output of the first question"],"metadata":{"id":"-rHxq1bmCkOf"}},{"cell_type":"code","source":["question_1 = df.Question[0]\n","answer_1 = answers[1]\n","print(\"Question 1: {}\".format(question_1))\n","print()\n","print(\"Answer: {}\".format(answer_1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D2anXcgGBXf1","executionInfo":{"status":"ok","timestamp":1663848709340,"user_tz":-120,"elapsed":618,"user":{"displayName":"Abdelrahman Ahmed","userId":"01921622983923456487"}},"outputId":"ddad3d39-9779-4087-d1f9-64d45d7d272e"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Question 1: What are the types of computer vision tasks?\n","\n","Answer: an interdisciplinary field that deals with how computers can be made to gain highlevel understanding from digital images or videos\n"]}]},{"cell_type":"markdown","source":["# Final DataFrame"],"metadata":{"id":"tIaMDq-DBiqP"}},{"cell_type":"code","source":["df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"4plWBX20DKFm","executionInfo":{"status":"ok","timestamp":1663848724108,"user_tz":-120,"elapsed":637,"user":{"displayName":"Abdelrahman Ahmed","userId":"01921622983923456487"}},"outputId":"dd6f0821-7f03-48fc-8996-d45e16bf9850"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0               Keyword  \\\n","0           0        digital images   \n","1           1       computer vision   \n","2           2            processing   \n","3           3  highdimensional data   \n","4           4      object detection   \n","\n","                                             Context  \\\n","0  The technological discipline of computer visio...   \n","1  The technological discipline of computer visio...   \n","2  Recent advances in deep learning has enabled r...   \n","3  Recent advances in deep learning has enabled r...   \n","4  From the perspective of engineering, it seeks ...   \n","\n","                                            Question  \n","0       What are the types of computer vision tasks?  \n","1         What is the definition of computer vision?  \n","2  What is the role of the input to a device for ...  \n","3         What is the definition of computer vision?  \n","4         What is the definition of computer vision?  "],"text/html":["\n","  <div id=\"df-4b938c1a-9226-4efe-8fd4-f7a92d53cef2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Keyword</th>\n","      <th>Context</th>\n","      <th>Question</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>digital images</td>\n","      <td>The technological discipline of computer visio...</td>\n","      <td>What are the types of computer vision tasks?</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>computer vision</td>\n","      <td>The technological discipline of computer visio...</td>\n","      <td>What is the definition of computer vision?</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>processing</td>\n","      <td>Recent advances in deep learning has enabled r...</td>\n","      <td>What is the role of the input to a device for ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>highdimensional data</td>\n","      <td>Recent advances in deep learning has enabled r...</td>\n","      <td>What is the definition of computer vision?</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>object detection</td>\n","      <td>From the perspective of engineering, it seeks ...</td>\n","      <td>What is the definition of computer vision?</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b938c1a-9226-4efe-8fd4-f7a92d53cef2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4b938c1a-9226-4efe-8fd4-f7a92d53cef2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4b938c1a-9226-4efe-8fd4-f7a92d53cef2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["df['Answers'] = answers"],"metadata":{"id":"QggL9120HKy6","executionInfo":{"status":"ok","timestamp":1663848807362,"user_tz":-120,"elapsed":9,"user":{"displayName":"Abdelrahman Ahmed","userId":"01921622983923456487"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"-YjUOVSAHgM6","executionInfo":{"status":"ok","timestamp":1663848815381,"user_tz":-120,"elapsed":357,"user":{"displayName":"Abdelrahman Ahmed","userId":"01921622983923456487"}},"outputId":"f92351bf-7998-4aef-d473-1b905c7a58c0"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0               Keyword  \\\n","0           0        digital images   \n","1           1       computer vision   \n","2           2            processing   \n","3           3  highdimensional data   \n","4           4      object detection   \n","\n","                                             Context  \\\n","0  The technological discipline of computer visio...   \n","1  The technological discipline of computer visio...   \n","2  Recent advances in deep learning has enabled r...   \n","3  Recent advances in deep learning has enabled r...   \n","4  From the perspective of engineering, it seeks ...   \n","\n","                                            Question  \\\n","0       What are the types of computer vision tasks?   \n","1         What is the definition of computer vision?   \n","2  What is the role of the input to a device for ...   \n","3         What is the definition of computer vision?   \n","4         What is the definition of computer vision?   \n","\n","                                             Answers  \n","0  methods for acquiring, processing, analyzing a...  \n","1  an interdisciplinary field that deals with how...  \n","2                                      vision sensor  \n","3  extraction of information from image data to d...  \n","4  methods for acquiring, processing, analyzing a...  "],"text/html":["\n","  <div id=\"df-080bb52d-99bf-407f-a68d-2ce634de76b1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Keyword</th>\n","      <th>Context</th>\n","      <th>Question</th>\n","      <th>Answers</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>digital images</td>\n","      <td>The technological discipline of computer visio...</td>\n","      <td>What are the types of computer vision tasks?</td>\n","      <td>methods for acquiring, processing, analyzing a...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>computer vision</td>\n","      <td>The technological discipline of computer visio...</td>\n","      <td>What is the definition of computer vision?</td>\n","      <td>an interdisciplinary field that deals with how...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>processing</td>\n","      <td>Recent advances in deep learning has enabled r...</td>\n","      <td>What is the role of the input to a device for ...</td>\n","      <td>vision sensor</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>highdimensional data</td>\n","      <td>Recent advances in deep learning has enabled r...</td>\n","      <td>What is the definition of computer vision?</td>\n","      <td>extraction of information from image data to d...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>object detection</td>\n","      <td>From the perspective of engineering, it seeks ...</td>\n","      <td>What is the definition of computer vision?</td>\n","      <td>methods for acquiring, processing, analyzing a...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-080bb52d-99bf-407f-a68d-2ce634de76b1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-080bb52d-99bf-407f-a68d-2ce634de76b1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-080bb52d-99bf-407f-a68d-2ce634de76b1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"4S6cEidTHl5f","executionInfo":{"status":"ok","timestamp":1663848899829,"user_tz":-120,"elapsed":639,"user":{"displayName":"Abdelrahman Ahmed","userId":"01921622983923456487"}},"outputId":"88d78f45-e523-40fe-8d43-803595d4e4af"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                Keyword                                            Context  \\\n","0        digital images  The technological discipline of computer visio...   \n","1       computer vision  The technological discipline of computer visio...   \n","2            processing  Recent advances in deep learning has enabled r...   \n","3  highdimensional data  Recent advances in deep learning has enabled r...   \n","4      object detection  From the perspective of engineering, it seeks ...   \n","\n","                                            Question  \\\n","0       What are the types of computer vision tasks?   \n","1         What is the definition of computer vision?   \n","2  What is the role of the input to a device for ...   \n","3         What is the definition of computer vision?   \n","4         What is the definition of computer vision?   \n","\n","                                             Answers  \n","0  methods for acquiring, processing, analyzing a...  \n","1  an interdisciplinary field that deals with how...  \n","2                                      vision sensor  \n","3  extraction of information from image data to d...  \n","4  methods for acquiring, processing, analyzing a...  "],"text/html":["\n","  <div id=\"df-7ce6dd70-be80-4b57-a87a-6c0d31764075\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Keyword</th>\n","      <th>Context</th>\n","      <th>Question</th>\n","      <th>Answers</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>digital images</td>\n","      <td>The technological discipline of computer visio...</td>\n","      <td>What are the types of computer vision tasks?</td>\n","      <td>methods for acquiring, processing, analyzing a...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>computer vision</td>\n","      <td>The technological discipline of computer visio...</td>\n","      <td>What is the definition of computer vision?</td>\n","      <td>an interdisciplinary field that deals with how...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>processing</td>\n","      <td>Recent advances in deep learning has enabled r...</td>\n","      <td>What is the role of the input to a device for ...</td>\n","      <td>vision sensor</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>highdimensional data</td>\n","      <td>Recent advances in deep learning has enabled r...</td>\n","      <td>What is the definition of computer vision?</td>\n","      <td>extraction of information from image data to d...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>object detection</td>\n","      <td>From the perspective of engineering, it seeks ...</td>\n","      <td>What is the definition of computer vision?</td>\n","      <td>methods for acquiring, processing, analyzing a...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ce6dd70-be80-4b57-a87a-6c0d31764075')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7ce6dd70-be80-4b57-a87a-6c0d31764075 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7ce6dd70-be80-4b57-a87a-6c0d31764075');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["df.to_csv(\"final_dataframe.csv\")"],"metadata":{"id":"kYqZuz6DH14M","executionInfo":{"status":"ok","timestamp":1663848964968,"user_tz":-120,"elapsed":8,"user":{"displayName":"Abdelrahman Ahmed","userId":"01921622983923456487"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DSDgyRi5IF5n"},"execution_count":null,"outputs":[]}]}